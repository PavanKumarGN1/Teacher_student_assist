{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip insatll "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'field_validator' from 'pydantic' (d:\\VS_Code\\teacher_student_assist\\teacher\\Lib\\site-packages\\pydantic\\__init__.cp311-win_amd64.pyd)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseLanguageModel\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseLLMOutputParser\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpydantic_v1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Field\n",
      "File \u001b[1;32md:\\VS_Code\\teacher_student_assist\\teacher\\Lib\\site-packages\\langchain_core\\language_models\\__init__.py:42\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"**Language Model** is a type of model that can generate text or complete\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mtext prompts.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m \n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     43\u001b[0m     BaseLanguageModel,\n\u001b[0;32m     44\u001b[0m     LangSmithParams,\n\u001b[0;32m     45\u001b[0m     LanguageModelInput,\n\u001b[0;32m     46\u001b[0m     LanguageModelLike,\n\u001b[0;32m     47\u001b[0m     LanguageModelOutput,\n\u001b[0;32m     48\u001b[0m     get_tokenizer,\n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseChatModel, SimpleChatModel\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FakeListLLM, FakeStreamingListLLM\n",
      "File \u001b[1;32md:\\VS_Code\\teacher_student_assist\\teacher\\Lib\\site-packages\\langchain_core\\language_models\\base.py:16\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cache\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     TYPE_CHECKING,\n\u001b[0;32m      8\u001b[0m     Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     Union,\n\u001b[0;32m     14\u001b[0m )\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel, ConfigDict, Field, field_validator\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TypeAlias, TypedDict, override\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'field_validator' from 'pydantic' (d:\\VS_Code\\teacher_student_assist\\teacher\\Lib\\site-packages\\pydantic\\__init__.cp311-win_amd64.pyd)"
     ]
    }
   ],
   "source": [
    "\"\"\"LLM Chain for generating examples for question answering.\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "from langchain_core.language_models.base import BaseLanguageModel\n",
    "from langchain_core.output_parsers import BaseLLMOutputParser\n",
    "from langchain_core.pydantic_v1 import Field\n",
    "\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.evaluation.qa.generate_prompt import PROMPT\n",
    "from langchain.output_parsers.regex import RegexParser\n",
    "\n",
    "_QA_OUTPUT_PARSER = RegexParser(\n",
    "    regex=r\"QUESTION: (.*?)\\n+ANSWER: (.*)\", output_keys=[\"query\", \"answer\"]\n",
    ")\n",
    "\n",
    "\n",
    "class QAGenerateChain(LLMChain):\n",
    "    \"\"\"LLM Chain for generating examples for question answering.\"\"\"\n",
    "\n",
    "    output_parser: BaseLLMOutputParser = Field(default=_QA_OUTPUT_PARSER)\n",
    "    output_key: str = \"qa_pairs\"\n",
    "\n",
    "    @classmethod\n",
    "    def is_lc_serializable(cls) -> bool:\n",
    "        return False\n",
    "\n",
    "    @classmethod\n",
    "    def from_llm(cls, llm: BaseLanguageModel, **kwargs: Any) -> QAGenerateChain:\n",
    "        \"\"\"Load QA Generate Chain from LLM.\"\"\"\n",
    "        return cls(llm=llm, prompt=PROMPT, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'field_validator' from 'pydantic' (d:\\VS_Code\\teacher_student_assist\\teacher\\Lib\\site-packages\\pydantic\\__init__.cp311-win_amd64.pyd)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mencoders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jsonable_encoder\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#from langchain.llms import CTransformers\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# from langchain.chains.qa_generation.base import QAGenerationChain\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# from langchain.text_splitter import RecursiveCharacterTextSplitter\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mqa_generation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CHAT_PROMPT \u001b[38;5;28;01mas\u001b[39;00m prompt\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Note: import PROMPT if using a legacy non-chat model.\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JsonOutputParser\n",
      "File \u001b[1;32md:\\VS_Code\\teacher_student_assist\\teacher\\Lib\\site-packages\\langchain\\chains\\qa_generation\\prompt.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# flake8: noqa\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompt_selector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConditionalPromptSelector, is_chat_model\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      4\u001b[0m     ChatPromptTemplate,\n\u001b[0;32m      5\u001b[0m     HumanMessagePromptTemplate,\n\u001b[0;32m      6\u001b[0m     SystemMessagePromptTemplate,\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n",
      "File \u001b[1;32md:\\VS_Code\\teacher_student_assist\\teacher\\Lib\\site-packages\\langchain\\chains\\prompt_selector.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mabc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ABC, abstractmethod\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, List, Tuple\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseLanguageModel\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseChatModel\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseLLM\n",
      "File \u001b[1;32md:\\VS_Code\\teacher_student_assist\\teacher\\Lib\\site-packages\\langchain_core\\language_models\\__init__.py:42\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"**Language Model** is a type of model that can generate text or complete\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mtext prompts.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m \n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     43\u001b[0m     BaseLanguageModel,\n\u001b[0;32m     44\u001b[0m     LangSmithParams,\n\u001b[0;32m     45\u001b[0m     LanguageModelInput,\n\u001b[0;32m     46\u001b[0m     LanguageModelLike,\n\u001b[0;32m     47\u001b[0m     LanguageModelOutput,\n\u001b[0;32m     48\u001b[0m     get_tokenizer,\n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseChatModel, SimpleChatModel\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FakeListLLM, FakeStreamingListLLM\n",
      "File \u001b[1;32md:\\VS_Code\\teacher_student_assist\\teacher\\Lib\\site-packages\\langchain_core\\language_models\\base.py:16\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cache\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     TYPE_CHECKING,\n\u001b[0;32m      8\u001b[0m     Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     Union,\n\u001b[0;32m     14\u001b[0m )\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel, ConfigDict, Field, field_validator\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TypeAlias, TypedDict, override\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'field_validator' from 'pydantic' (d:\\VS_Code\\teacher_student_assist\\teacher\\Lib\\site-packages\\pydantic\\__init__.cp311-win_amd64.pyd)"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, Form, Request, Response, File, Depends, HTTPException, status\n",
    "from fastapi.responses import RedirectResponse\n",
    "from fastapi.staticfiles import StaticFiles\n",
    "from fastapi.templating import Jinja2Templates\n",
    "from fastapi.encoders import jsonable_encoder\n",
    "#from langchain.llms import CTransformers\n",
    "from langchain.chains.qa_generation.base import QAGenerationChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chains import RetrievalQA\n",
    "import os \n",
    "import json\n",
    "import time\n",
    "import uvicorn\n",
    "import aiofiles\n",
    "from PyPDF2 import PdfReader\n",
    "import csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI()\n",
    "\n",
    "app.mount(\"/static\", StaticFiles(directory=\"static\"), name=\"static\")\n",
    "\n",
    "templates = Jinja2Templates(directory=\"templates\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install ctransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\VS_Code\\teacher_student_assist\\teacher\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_llm():\n",
    "    # Load the locally downloaded model here\n",
    "    llm = AutoModelForCausalLM.from_pretrained(\n",
    "        url=\"https://rag-llm-api.accubits.cloud/v1/chat/completions\",\n",
    "        model = \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "        api_key=\"budserve_2T9wfwNiiALTt7UAQZCoGuLPAUUTZras9cLUpYZ1\",\n",
    "        model_type=\"meta-llama\",\n",
    "        max_new_tokens = 500,\n",
    "        temperature = 0.3\n",
    "    )\n",
    "    return llm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import CTransformers\n",
    "\n",
    "\n",
    "llm = CTransformers(\n",
    "    model=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    api_key=\"budserve_2T9wfwNiiALTt7UAQZCoGuLPAUUTZras9cLUpYZ1\",\n",
    "    model_type=\"meta-llama\",    \n",
    "    max_new_tokens = 500,    \n",
    "    temperature = 0.3    )\n",
    "\n",
    "print(llm.invoke('AI is going to'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "Here are 5 multiple-choice questions based on the text:\n",
      "\n",
      "Question 1: What is the capital of India?\n",
      "A) Mumbai\n",
      "B) New Delhi\n",
      "C) Agra\n",
      "D) Uttar Pradesh\n",
      "\n",
      "Correct answer: B) New Delhi\n",
      "\n",
      "Question 2: Which city is the location of the Taj Mahal?\n",
      "A) New Delhi\n",
      "B) Agra\n",
      "C) Mumbai\n",
      "D) Uttar Pradesh\n",
      "\n",
      "Correct answer: B) Agra\n",
      "\n",
      "Question 3: Which state is the location of Agra?\n",
      "A) Punjab\n",
      "B) Uttar Pradesh\n",
      "C) Maharashtra\n",
      "D) Gujarat\n",
      "\n",
      "Correct answer: B) Uttar Pradesh\n",
      "\n",
      "Question 4: What is the name of the famous monument located in Agra?\n",
      "A) Red Fort\n",
      "B) Qutub Minar\n",
      "C) Taj Mahal\n",
      "D) Humayun's Tomb\n",
      "\n",
      "Correct answer: C) Taj Mahal\n",
      "\n",
      "Question 5: Is Agra located in the state of New Delhi?\n",
      "A) Yes\n",
      "B) No\n",
      "C) Maybe\n",
      "D) Not mentioned\n",
      "\n",
      "Correct answer: B) No\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Replace with your actual API key\n",
    "api_key = 'budserve_AorbBLLqy97G7dwGiPH5TDvqvkanMaUCybE8GrHu'\n",
    "\n",
    "def generate_mcqs(text, num_questions=5):\n",
    "    url = 'https://rag-llm-api.accubits.cloud/v1/chat/completions'\n",
    "    headers = {\n",
    "        'api-key': api_key,\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "        \"max_tokens\": 500,\n",
    "        \"stream\": True,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"This is a chat between a user and an artificial intelligence assistant\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Generate {num_questions} multiple-choice questions from the following text:\\n\\n{text}\\n\\nEach question should have four options and one correct answer.\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(payload), stream=True)\n",
    "\n",
    "    mcqs = ''\n",
    "    try:\n",
    "        for chunk in response.iter_lines():\n",
    "            if chunk:\n",
    "                chunk_data = chunk.decode('utf-8').replace('data: ', '')\n",
    "                if chunk_data:\n",
    "                    try:\n",
    "                        chunk_json = json.loads(chunk_data)\n",
    "                        if 'choices' in chunk_json and chunk_json['choices'][0]['delta'].get('content'):\n",
    "                            mcqs += chunk_json['choices'][0]['delta']['content']\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"Error decoding JSON: {e}\")\n",
    "                        continue\n",
    "        return mcqs.strip()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "text = \"The capital of India is New Delhi. The Taj Mahal is located in Agra, Uttar Pradesh.\"\n",
    "mcqs = generate_mcqs(text)\n",
    "if mcqs:\n",
    "    print(mcqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Replace with your actual API key\n",
    "api_key = 'budserve_AorbBLLqy97G7dwGiPH5TDvqvkanMaUCybE8GrHu'\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    print(f\"Extracted text length: {len(text)}\")\n",
    "    return text\n",
    "\n",
    "def generate_mcqs(text, num_questions=5):\n",
    "    url = 'https://rag-llm-api.accubits.cloud/v1/chat/completions'\n",
    "    headers = {\n",
    "        'api-key': api_key,\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "        \"max_tokens\": 500,\n",
    "        \"stream\": True,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"This is a chat between a user and an artificial intelligence assistant\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Generate {num_questions} multiple-choice questions from the following text:\\n\\n{text}\\n\\nEach question should have four options and one correct answer.\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(payload), stream=True)\n",
    "    mcqs = ''\n",
    "    try:\n",
    "        for chunk in response.iter_lines():\n",
    "            if chunk:\n",
    "                chunk_data = chunk.decode('utf-8').replace('data: ', '')\n",
    "                if chunk_data:\n",
    "                    try:\n",
    "                        chunk_json = json.loads(chunk_data)\n",
    "                        if 'choices' in chunk_json and chunk_json['choices'][0]['delta'].get('content'):\n",
    "                            mcqs += chunk_json['choices'][0]['delta']['content']\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"Error decoding JSON: {e}\")\n",
    "                        continue\n",
    "        return mcqs.strip()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request error: {e}\")\n",
    "        return None\n",
    "\n",
    "def split_text(text, max_length=8000):\n",
    "    sentences = text.split('. ')\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    for sentence in sentences:\n",
    "        if len(current_chunk) + len(sentence) + 1 <= max_length:\n",
    "            current_chunk += sentence + \". \"\n",
    "        else:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence + \". \"\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    return chunks\n",
    "\n",
    "# Example usage\n",
    "pdf_path = r'D:\\VS_Code\\teacher_student_assist\\students\\temp\\jesc101.pdf'\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "text_chunks = split_text(pdf_text)\n",
    "\n",
    "mcqs = \"\"\n",
    "for chunk in text_chunks:\n",
    "    result = generate_mcqs(chunk)\n",
    "    if result:\n",
    "        mcqs += result + \"\\n\\n\"\n",
    "\n",
    "print(mcqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text length: 31769\n",
      "Time taken to extract text: 0.42 seconds\n",
      "Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "Time taken to generate MCQs: 30.80 seconds\n",
      "Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "Time taken to generate MCQs: 26.36 seconds\n",
      "Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "Time taken to generate MCQs: 25.27 seconds\n",
      "Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "Time taken to generate MCQs: 12.00 seconds\n",
      "Error decoding JSON: Expecting value: line 1 column 2 (char 1)\n",
      "Time taken to generate MCQs: 23.35 seconds\n",
      "Here are five multiple-choice questions based on the provided text:\n",
      "\n",
      "Question 1: What is the name of the powder formed when magnesium ribbon is burnt in air?\n",
      "\n",
      "A) Magnesium oxide\n",
      "B) Zinc oxide\n",
      "C) Iron oxide\n",
      "D) Lead oxide\n",
      "\n",
      "Correct answer: A) Magnesium oxide\n",
      "\n",
      "Question 2: What is the purpose of balancing a chemical equation?\n",
      "\n",
      "A) To make the equation_PROD longer\n",
      "B) To make the equation_RED longer\n",
      "C) To ensure that the number of atoms of each element is the same on both sides of the equation\n",
      "D) To make the equation_WRITTEN longer\n",
      "\n",
      "Correct answer: C) To ensure that the number of atoms of each element is the same on both sides of the equation\n",
      "\n",
      "Question 3: What is the name of the law that states that mass can neither be created nor destroyed in a chemical reaction?\n",
      "\n",
      "A) Law of Conservation of Energy\n",
      "B) Law of Conservation of Mass\n",
      "C) Law of Chemical Reactions\n",
      "D) Law of Physical Changes\n",
      "\n",
      "Correct answer: B) Law of Conservation of Mass\n",
      "\n",
      "Question 4: What is the purpose of drawing boxes around each formula while balancing aümü chemical equation?\n",
      "\n",
      "A) To change the formulae of the compounds or elements involved in the reactions\n",
      "B) To ensure that the number of atoms of each element is the same on both sides of the equation\n",
      "C) To make the equation longer\n",
      "D) Touyếnalter the formulae of the compounds or elements involved in the reactions\n",
      "\n",
      "Correct answer: B) To ensure that the number of atoms of each element is the same on both sides of the equation\n",
      "\n",
      "Question 5: What is the name of the process by which substances undergo chemical change?\n",
      "\n",
      "A) Physical change\n",
      "B) Chemical reaction\n",
      "C) Chemical equation\n",
      "D) Chemical formula\n",
      "\n",
      "Correct answer: B) Chemical reaction\n",
      "\n",
      "Here are five multiple-choice questions based on the provided text:\n",
      "\n",
      "Question 1: What is the type of reaction that occurs when calcium oxide reacts with water to produce slaked lime?\n",
      "\n",
      "A) Decomposition reaction\n",
      "B) Combination reaction\n",
      "C) Neutralization reaction\n",
      "D) Oxidation reaction\n",
      "\n",
      "Correct answer: B) Combination reaction\n",
      "\n",
      "Question 2: What is the balanced equation for the reaction between hydrogen and chlorine to produce hydrogen chloride?\n",
      "\n",
      "A) 2H2 + Cl2 → 2HCl\n",
      "B) H2 + Cl2 → HCl\n",
      "C) 4H2 + 2Cl2 → 4HCl\n",
      "D) H2 + 2Cl2 → 2HCl\n",
      "\n",
      "Correct answer: A) 2H2 + Cl2 → 2HCl\n",
      "\n",
      "Question 3: What is the physical state of water in the reaction between barium chloride and sodium sulphate?\n",
      "\n",
      "A) Solid\n",
      "B) Liquid\n",
      "C) Gas\n",
      "D) Aqueous\n",
      "\n",
      "Correct answer: D) Aqueous\n",
      "\n",
      "Question 4: What is the type of reaction that occurs during the decomposition of vegetable matter into compost?\n",
      "\n",
      "A) Exothermic reaction\n",
      "B) Endothermic reaction\n",
      "C Curie reaction\n",
      "D) Radioactive reaction\n",
      "\n",
      "Correct answer: A) Exothermic reaction\n",
      "\n",
      "Question 5: What is the product formed when calcium hydroxide reacts slowly with carbon dioxide in air?\n",
      "\n",
      "A) Calcium carbonate\n",
      "B) Calcium oxide\n",
      "C) Calcium chloride\n",
      "D) Calcium nitrate\n",
      "\n",
      "Correct answer: A) Calcium carbonate\n",
      "\n",
      "Here are five multiple-choice questions based on the provided text:\n",
      "\n",
      "**Question 1**\n",
      "What is the color of the ferrous sulphate crystals after heating?\n",
      "a) Green\n",
      "b) Blue\n",
      "c) Grey\n",
      "d) Black\n",
      "\n",
      "Correct answer: c) Grey\n",
      "\n",
      "**Question 2**\n",
      "What type of reaction occurs when silver chloride is exposed to sunlight?\n",
      "a) Decomposition reaction\n",
      "b) Displacement reaction\n",
      "c) Double displacement reaction\n",
      "d) Oxidation reaction\n",
      "\n",
      "Correct answer: a) Decomposition reaction\n",
      "\n",
      "**Question 3**\n",
      "What is the purpose of adding a few drops of dilute sulphuric acid to the water in Activity 1.7?\n",
      "a) To increase the volume of the gas collected\n",
      "b) To decrease the volume of the gas collected\n",
      "c) To facilitate the electrolysis of water\n",
      "d) To change the color of the electrodes\n",
      "\n",
      "Correct answer: c) To facilitate the electrolysis of water\n",
      "\n",
      "**Question 4**\n",
      "What is the name of the reaction that occurs when a more reactive element displaces a less reactive element from its compound?\n",
      "a) Decomposition reaction\n",
      "b) Displacement reaction\n",
      "c) Double displacement reaction\n",
      "d) Oxidation reaction\n",
      "\n",
      "Correct answer: b) Displacement reaction\n",
      "\n",
      "**Question 5**\n",
      "What type of reaction occurs when copper powder is heated in the presence of oxygen?\n",
      "a) Decomposition reaction\n",
      "b) Displacement reaction\n",
      "c) Oxidation reaction\n",
      "d) Double displacement reaction\n",
      "\n",
      "Correct answer: c) Oxidation reaction\n",
      "\n",
      "Here are five multiple-choice questions based on the provided text:\n",
      "\n",
      "**Question 1**\n",
      "Why does the colour of copper sulphate solution change when an iron nail is dipped in it?\n",
      "\n",
      "A) Because iron displaces copper from copper sulphate.\n",
      "B) Because oxygen is released from the reaction.\n",
      "C) Because copper is oxidised to form copper oxide.\n",
      "D) Because the solution becomes more concentrated.\n",
      "\n",
      "**Correct answer:** A) Because iron displaces copper from copper sulphate.\n",
      "\n",
      "**Question 2**\n",
      "What is an example of a double displacement reaction other than the one given in Activity 1.10?\n",
      "\n",
      "A) Zinc carbonate decomposing into zinc oxide and carbon dioxide.\n",
      "_SOLVED_\n",
      "\n",
      "Here are 5 multiple-choice questions based on the text:\n",
      "\n",
      "**Question 1**\n",
      "Why are decomposition reactions called the opposite of combination reactions?\n",
      "\n",
      "A) Because they involve the formation of a new compound\n",
      "B) Because they involve the breakdown of a compound into simpler substances\n",
      "C) Because they require more energy\n",
      "D) Because they occur at a higher temperature\n",
      "\n",
      "Correct answer: B) Because they involve the breakdown of a compound into simpler substances\n",
      "\n",
      "**Question 2**\n",
      "What type of reaction is the decomposition of copper sulphate solution?\n",
      "\n",
      "A) Combination reaction\n",
      "B) Decomposition reaction\n",
      "C) Displacement reaction\n",
      "D) Double displacement reaction\n",
      "\n",
      "Correct answer: B) Decomposition reaction\n",
      "\n",
      "**Question 3**\n",
      "What happens when oil and fat-containing food items are flushed with nitrogen?\n",
      "\n",
      "A) They become spoiled\n",
      "B) They become rancid\n",
      "C) They are preserved\n",
      "D) They are cooked\n",
      "\n",
      "Correct answer: C) They are preserved\n",
      "\n",
      "**Question 4**\n",
      "What is the purpose of applying paint on iron articles?\n",
      "\n",
      "A) To make them look shiny\n",
      "B) To protect them from corrosion\n",
      "C) To make them heavier\n",
      "D) To make them lighter\n",
      "\n",
      "Correct answer: B) To protect them from corrosion\n",
      "\n",
      "**Question 5**\n",
      "What is the result of oxidation on a shiny brown element 'X' when it is heated in air?\n",
      "\n",
      "A) It becomes reddish in color\n",
      "B) It becomes black in color\n",
      "C) It becomes transparent\n",
      "D) It becomes white in color\n",
      "\n",
      "Correct answer: B) It becomes black in color\n",
      "\n",
      "\n",
      "Total execution time: 117.79 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "######## pdf mcqs ########\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Replace with your actual API key\n",
    "api_key = 'budserve_AorbBLLqy97G7dwGiPH5TDvqvkanMaUCybE8GrHu'\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    start_time = time.time()\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    end_time = time.time()\n",
    "    print(f\"Extracted text length: {len(text)}\")\n",
    "    print(f\"Time taken to extract text: {end_time - start_time:.2f} seconds\")\n",
    "    return text\n",
    "\n",
    "def generate_mcqs(text, num_questions=5):\n",
    "    url = 'https://rag-llm-api.accubits.cloud/v1/chat/completions'\n",
    "    headers = {\n",
    "        'api-key': api_key,\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "        \"max_tokens\": 500,\n",
    "        \"stream\": True,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"This is a chat between a user and an artificial intelligence assistant\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Generate {num_questions} multiple-choice questions from the following text:\\n\\n{text}\\n\\nEach question should have four options and one correct answer.\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(payload), stream=True)\n",
    "    mcqs = ''\n",
    "    try:\n",
    "        for chunk in response.iter_lines():\n",
    "            if chunk:\n",
    "                chunk_data = chunk.decode('utf-8').replace('data: ', '')\n",
    "                if chunk_data:\n",
    "                    try:\n",
    "                        chunk_json = json.loads(chunk_data)\n",
    "                        if 'choices' in chunk_json and chunk_json['choices'][0]['delta'].get('content'):\n",
    "                            mcqs += chunk_json['choices'][0]['delta']['content']\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"Error decoding JSON: {e}\")\n",
    "                        continue\n",
    "        end_time = time.time()\n",
    "        print(f\"Time taken to generate MCQs: {end_time - start_time:.2f} seconds\")\n",
    "        return mcqs.strip()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request error: {e}\")\n",
    "        return None\n",
    "\n",
    "def split_text(text, max_length=8000):\n",
    "    sentences = text.split('. ')\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    for sentence in sentences:\n",
    "        if len(current_chunk) + len(sentence) + 1 <= max_length:\n",
    "            current_chunk += sentence + \". \"\n",
    "        else:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence + \". \"\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    return chunks\n",
    "\n",
    "# Example usage\n",
    "pdf_path = r'D:\\VS_Code\\teacher_student_assist\\students\\temp\\jesc101.pdf'\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "text_chunks = split_text(pdf_text)\n",
    "\n",
    "mcqs = \"\"\n",
    "start_time_total = time.time()\n",
    "for chunk in text_chunks:\n",
    "    result = generate_mcqs(chunk)\n",
    "    if result:\n",
    "        mcqs += result + \"\\n\\n\"\n",
    "end_time_total = time.time()\n",
    "\n",
    "print(mcqs)\n",
    "print(f\"Total execution time: {end_time_total - start_time_total:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 5 chunks from Qdrant\n",
      "Time taken to retrieve chunks: 0.86 seconds\n",
      "Sending chunk to model: Chemical Reactions and Equations 1 CHAPTER C onsider the following situations of daily life and think what happens when – n milk is left at room temperature during summers. n an iron tawa/pan/nail is left exposed to humid atmosphere. n grapes get fermented. n food is cooked. n food gets digested in our body. n we respire. In all the above situations, the nature and the identity of the initial substance have somewhat changed. We have already learnt about physical and chemical changes of matter in...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "########## qdrant mcqs ########\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "\n",
    "# Replace with your actual API key and ensure it's securely handled\n",
    "api_key = 'budserve_AorbBLLqy97G7dwGiPH5TDvqvkanMaUCybE8GrHu'\n",
    "\n",
    "# Set Qdrant connection details\n",
    "QDRANT_URL = os.getenv('QDRANT_URL') or \"your_qdrant_url_here\"  # Replace with actual Qdrant URL if not in env\n",
    "QDRANT_API_KEY = os.getenv('QDRANT_API_KEY') or \"your_qdrant_api_key_here\"  # Replace with actual Qdrant API Key\n",
    "\n",
    "# Connect to Qdrant instance\n",
    "qdrant_client = QdrantClient(\n",
    "    url=QDRANT_URL,\n",
    "    api_key=QDRANT_API_KEY\n",
    ")\n",
    "collection_name = \"document_embeddings\"\n",
    "\n",
    "def get_chunks_from_qdrant(collection_name):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        # Retrieve documents from Qdrant collection\n",
    "        response = qdrant_client.scroll(collection_name=collection_name, with_payload=True)\n",
    "        text_chunks = [hit.payload.get('chunk', '') for hit in response[0] if hit.payload.get('chunk', '')]\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"Retrieved {len(text_chunks)} chunks from Qdrant\")\n",
    "        print(f\"Time taken to retrieve chunks: {end_time - start_time:.2f} seconds\")\n",
    "        \n",
    "        if not text_chunks:\n",
    "            print(\"No text chunks were found. Please verify the collection contains data with 'text' fields.\")\n",
    "        \n",
    "        return text_chunks\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving chunks from Qdrant: {e}\")\n",
    "        return []\n",
    "\n",
    "def generate_mcqs(text_chunk, num_questions=5):\n",
    "    url = 'https://rag-llm-api.accubits.cloud/v1/chat/completions'\n",
    "    headers = {\n",
    "        'api-key': api_key,\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "        \"max_tokens\": 500,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an AI assistant designed to create multiple-choice questions (MCQs) from the provided text. Ensure each MCQ has four options and one correct answer.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Here is the text: {text_chunk}. Create {num_questions} multiple-choice questions.\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    print(f\"Sending chunk to model: {text_chunk[:500]}...\")  # Print first 500 characters for checking\n",
    "    start_time = time.time()\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "    try:\n",
    "        response_json = response.json()\n",
    "        mcqs = response_json['choices'][0]['message']['content']\n",
    "        end_time = time.time()\n",
    "        print(f\"Time taken to generate MCQs: {end_time - start_time:.2f} seconds\")\n",
    "        return mcqs.strip()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request error: {e}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "        print(f\"Response text: {response.text}\")\n",
    "        return None\n",
    "    except KeyError as e:\n",
    "        print(f\"Key error: {e}\")\n",
    "        print(f\"Response structure: {response_json}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "text_chunks = get_chunks_from_qdrant(collection_name)\n",
    "\n",
    "mcqs = \"\"\n",
    "start_time_total = time.time()\n",
    "for chunk in text_chunks:\n",
    "    result = generate_mcqs(chunk)\n",
    "    if result:\n",
    "        mcqs += result + \"\\n\\n\"\n",
    "end_time_total = time.time()\n",
    "\n",
    "print(mcqs)\n",
    "print(f\"Total execution time: {end_time_total - start_time_total:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
